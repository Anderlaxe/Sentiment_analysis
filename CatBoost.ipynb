{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "N_LABELS = len(LABELS)\n",
    "\n",
    "train = pd.read_csv('../../Data/train.csv')\n",
    "test = pd.read_csv('../../Data/test.csv')\n",
    "test_labels = pd.read_csv('../../Data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern form filtering english stopwords, taken from https://stackoverflow.com/questions/19560498/faster-way-to-remove-stop-words-in-python\n",
    "stopword_pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "\n",
    "# Preprocessing\n",
    "def preprocessComments(comment):\n",
    "    # Remove leading and trailing spaces\n",
    "    comment = comment.strip()\n",
    "\n",
    "    # Remove stopwords\n",
    "    comment = stopword_pattern.sub('', comment)\n",
    "    \n",
    "    # Remove numbers\n",
    "    comment = re.sub(r'[0-9]', '', comment)\n",
    "\n",
    "    # Remove anything that is not alphanumeric characters or underscore\n",
    "    comment = re.sub(r'[^\\w\\s]', '', comment)\n",
    "\n",
    "    # Remove consecutive spaces      \n",
    "    comment = re.sub(r' +', ' ', comment)\n",
    "\n",
    "    # Remove Newlines\n",
    "    comment = re.sub(r'\\n', ' ', comment)\n",
    "\n",
    "    return comment\n",
    "\n",
    "train.comment_text = train.comment_text.map(preprocessComments)\n",
    "test.comment_text = test.comment_text.map(preprocessComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filtered = pd.merge(test, test_labels)\n",
    "test_filtered = test_filtered.drop(test_filtered.index[test_filtered['toxic'] == -1])\n",
    "test_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy = test_labels.to_numpy()\n",
    "test_numpy = test_numpy[:, 1:]\n",
    "test_numpy = test_numpy.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside a validation set of 20%\n",
    "train_set, validation_set = train_test_split(train, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Pool datassets into labels\n",
    "def createPool(dataset, use_label=True):\n",
    "    current = {}\n",
    "    for label in LABELS:\n",
    "        if use_label:\n",
    "            current[label] = catboost.Pool(dataset[['comment_text']], text_features=['comment_text'], label=dataset[label])\n",
    "        else:\n",
    "            current[label] = catboost.Pool(dataset[['comment_text']], text_features=['comment_text'])\n",
    "    return current\n",
    "\n",
    "\n",
    "train_pools = createPool(train_set)\n",
    "val_pools = createPool(validation_set)\n",
    "test_pools = createPool(test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for label in LABELS:\n",
    "    print(label)\n",
    "    models[label] = catboost.CatBoostClassifier(\n",
    "        learning_rate=0.3,\n",
    "        iterations=5000,\n",
    "        eval_metric='F1',\n",
    "        od_wait=350,\n",
    "        od_type='Iter',\n",
    "        random_seed=SEED)\n",
    "        \n",
    "    models[label].fit(\n",
    "        train_pools[label], \n",
    "        eval_set=val_pools[label], \n",
    "        verbose=100,\n",
    "        early_stopping_rounds=350, \n",
    "        use_best_model=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.ndarray((test_filtered.shape[0], N_LABELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.ndarray((test_filtered.shape[0], N_LABELS))\n",
    "\n",
    "avg = 0\n",
    "for i, label in enumerate(LABELS):\n",
    "    print(label, \":\")\n",
    "    predictions[:, i] = models[label].predict(test_pools[label])\n",
    "    score = f1_score(test_filtered[label], predictions[:, i])\n",
    "    print(score)\n",
    "    avg += score\n",
    "\n",
    "avg /= N_LABELS\n",
    "print(\"Average f1-score:\", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "\n",
    "for label in LABELS:\n",
    "    models[label].save_model(\"./catboost_models/\" + label + \"_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and rerun preds\n",
    "models = {}\n",
    "\n",
    "for label in LABELS:\n",
    "    models[label] = catboost.CatBoostClassifier()\n",
    "    models[label].load_model(\"./catboost_models/\" + label + \"_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.ndarray((test_filtered.shape[0], N_LABELS))\n",
    "avg = 0\n",
    "for i, label in enumerate(LABELS):\n",
    "    print(label, \":\")\n",
    "    p = models[label].predict_proba(test_pools[label])\n",
    "    predictions[:, i] = (p[:, 1] >= 0.5)\n",
    "    score = f1_score(test_filtered[label], predictions[:, i])\n",
    "    score = f1_score(test_filtered[label], predictions[:, i])\n",
    "    print(score)\n",
    "    avg += score\n",
    "\n",
    "avg /= N_LABELS\n",
    "print(\"Average f1-score:\", avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in LABELS:\n",
    "    test_filtered[label] = models[label].predict_proba(test_pools[label])[:, 1]\n",
    "test_filtered.to_csv('catboost_predictions_raw.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
